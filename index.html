<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multiplur Chatbot</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
</head>
<body>
    <div id="chat-container">
        <div id="chat-messages"></div>
        <input type="text" id="user-input" placeholder="Type your message...">
        <button onclick="sendMessage()">Send</button>
    </div>

    <script>
        let model;
        let labelEncoder;
        let intentResponses;

        async function loadModel() {
            try {
                // Load the model.json file
                const modelResponse = await fetch('model/model.json');
                let modelJSON = await modelResponse.json();
        
                // Modify the input layer to accept any batch size
                modelJSON.modelTopology.model_config.config.layers[0].config.batch_input_shape = [null, 50];
        
                // Convert snake_case to camelCase for all keys in the JSON
                function convertKeys(obj) {
                    if (typeof obj !== 'object' || obj === null) {
                        return obj;
                    }
                    if (Array.isArray(obj)) {
                        return obj.map(convertKeys);
                    }
                    return Object.keys(obj).reduce((acc, key) => {
                        const camelKey = key.replace(/_([a-z])/g, (g) => g[1].toUpperCase());
                        acc[camelKey] = convertKeys(obj[key]);
                        return acc;
                    }, {});
                }
        
                modelJSON = convertKeys(modelJSON);
        
                // Load the model with the modified JSON
                model = await tf.loadLayersModel(tf.io.fromMemory(modelJSON));
                
                const labelEncoderResponse = await fetch('model/label_encoder.json');
                labelEncoder = await labelEncoderResponse.json();
                const intentResponsesResponse = await fetch('intent_responses.json');
                intentResponses = await intentResponsesResponse.json();
                await loadTokenizer();  // Load the tokenizer
                console.log('Model and data loaded successfully');
            } catch (error) {
                console.error('Error loading model or data:', error);
            }
        }

        let tokenizer;
        let word_index;
        
        async function loadTokenizer() {
            const response = await fetch('model/tokenizer.json');
            const outerJson = await response.json();
            tokenizer = JSON.parse(outerJson);
            word_index = JSON.parse(tokenizer.config.word_index);
        }
        
        function preprocess(text) {
            if (!word_index) {
                console.error('Tokenizer not properly loaded');
                return null;
            }
            const words = text.toLowerCase().split(' ');
            const sequence = words.map(word => word_index[word] || 1); // 1 is <OOV> token
            const padded = padSequence(sequence, 50);  // 50 is the input sequence length
            return tf.tensor2d([padded]);
        }
        
        function padSequence(sequence, maxLen) {
            if (sequence.length > maxLen) {
                return sequence.slice(0, maxLen);
            }
            return [...sequence, ...new Array(maxLen - sequence.length).fill(0)];
        }

        async function classifyIntent(userInput) {
            const inputTensor = preprocess(userInput);
            if (!inputTensor) {
                return 'error';
            }
            const prediction = await model.predict(inputTensor).array();
            const intentIndex = prediction[0].indexOf(Math.max(...prediction[0]));
            return labelEncoder[intentIndex];
        }

        function getResponse(intent, query) {
            if (intent in intentResponses) {
                return intentResponses[intent][Math.floor(Math.random() * intentResponses[intent].length)];
            } else {
                return "I'm not sure how to respond to that. Could you please rephrase your question?";
            }
        }

        async function sendMessage() {
            const userInput = document.getElementById('user-input').value;
            document.getElementById('user-input').value = '';
            
            displayMessage('User: ' + userInput);
            
            try {
                const intent = await classifyIntent(userInput);
                const response = getResponse(intent, userInput);
                displayMessage('Chatbot: ' + response);
            } catch (error) {
                console.error('Error processing message:', error);
                displayMessage('Chatbot: Sorry, I encountered an error. Please try again.');
            }
        }

        function displayMessage(message) {
            const chatMessages = document.getElementById('chat-messages');
            const messageElement = document.createElement('p');
            messageElement.textContent = message;
            chatMessages.appendChild(messageElement);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }
        

        loadModel();
    </script>
</body>
</html>
